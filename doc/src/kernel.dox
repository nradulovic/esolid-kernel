/** @file */
/** @defgroup   kernel Kernel
@brief          Overview
@{
@defgroup       kern_intf Interface
@defgroup       kern_impl Internals
@defgroup       kern_cfg  Configuration
@} */

/** @addtogroup kern_intf
@brief          Application programming interface
*/

/** @addtogroup kern_impl
@brief          Kernel inner work
*/

/** @addtogroup kern_cfg
@brief          Configuration settings
*/

/** @defgroup   template Port template
@brief          Templates
@{
@defgroup       template_compiler   Compiler port
@defgroup       template_cpu_intf   CPU port interface
@defgroup       template_cpu_impl   CPU port internals
@defgroup       template_cpu_cfg    CPU port configuration
@defgroup       template_kern_cfg   Kernel configuration
@} */

/** @addtogroup template_compiler
@brief          Compiler provided macros and data types
*/

/** @addtogroup template_cpu_intf
@brief          CPU port macros and functions
*/

/** @addtogroup template_cpu_impl
@brief          CPU port inner work
*/

/** @addtogroup template_cpu_cfg
@brief          CPU port specific configuration options
*/

/** @addtogroup template_kern_cfg
@brief          Default Kernel configuration options
*/
/*----------------------------------------------------------------------------*/
/** @mainpage   eSolid Real-Time Kernel
@section        kernel_specs eSolid RT Kernel Specification
@subsection     spec_source Source code

The source code of the kernel and all of it's ports are published under <b>free 
software license</b>, which guarantees end users (individuals, organizations, 
companies) the freedoms to use, study, share (copy), and modify the software. 

The GPL grants the recipients of a computer software the rights of the Free 
Software Definition (written by Richard Stallman) and uses copyleft to ensure 
the freedoms are preserved whenever the work is distributed, even when the work 
is changed or added to. The GPL is a copyleft license, which means that derived
works can only be distributed under the same license terms.

For more details visit: https://gnu.org/licenses/gpl.html

@subsection     spec_api Consistent Application Programming Interface

All objects declared in Application Programming Interface are following
these naming rules:
- All objects except macros are using @c CamelCase style names
- All functions, structures and unions are prefixed with: @c es
- All typedef-ed types are prefixed with: @c es and postfixed with: @c _T
- All macro names are in @c UPPERCASE style, words are delimited by underscore 
    sign
- All macro names are prefixed with: @c ES_
- All Global variables are prefixed with: @c g

All API objects are named following this convention: 
<code>es<group><action><suffix>()</code>

- Group:
    - @c Kern - General Kernel services
    - @c Thd - Thread management
    - @c ThdQ - Thread Queue management
    - @c Sched - Scheduler invocation
    - @c SchedRdy - Scheduler Ready Thread Queue management
- Suffix:
    - none - normal API object
    - I - I class - Regular Interrupts are locked

All Port Interface objects are named using the rules stated above with certain
differences:
- All functions, structures and unions are prefixed with: @c port
- All macro names are prefixed with: @c PORT_

@subsection     spec_preempt Preemptive multi-threading
eSolid RT Kernel uses a <b>preemptive scheduler</b>, which has the power to 
preempt, or interrupt, and later resume, other threads in the system. The 
scheduler always runs ready thread with the highest priority.

@subsection     spec_rr Round-Robin scheduling
Round-Robin scheduling is very <b>simple algorithm</b> to implement and it is 
<b>starvation free</b>. It employs time-sharing, giving to each thread a time 
slice or @c quantum. Processor's time is shared between a number of threads, 
giving the illusion that it is dealing with these threads <b>concurrently</b>. 
This scheduling is only used when there are two or more threads of the same 
priority ready for execution.

@subsection     spec_deterministic Deterministic
All algorithms used in eSolid RT Kernel implementation are belonging to 
<b>Constant Time Complexity</b> category. Constant Time <code>O(1)</code> 
functions needs fixed amount of time to execute an algorithm. Their execution 
time does not depend on number of inputs. For more information see 
@ref time_complexity.

@subsection     spec_cfg Configurable
The kernel provides two configuration files kernel_cfg.h and cpu_cfg.h which can
be used to tailor the kernel to application needs.

In addition, the kernel implements a number of hooks which can alter or augment 
the behavior of the kernel or applications, by intercepting function calls 
between software components.

@subsection     spec_portable Portable
During the design stage of the kernel a special attention was given to achieve
high portability of the kernel. Some data types and algorithms are tailored to
exploit new hardware features.

@subsection     spec_static Static object allocation
All objects used in eSolid RT Kernel can be statically allocated. There is no
need to use any memory management functionality which makes it very easy to
verify the application.

@subsection     spec_unlimited Unlimited number of threads
eSolid RT Kernel allows applications to have any number of threads. The only 
limiting factors for the maximum number of threads are the amount of RAM and 
ROM memory capacity and required processing time.

@subsection     spec_errchk Error checking
All eSolid software is using design methods very similar to approaches of
<b>contract programming</b> paradigm for software design. The contract
programming prescribes that Application Programming Interface should have formal, 
precise and verifiable specifications, which extend the ordinary definition of 
abstract data types with preconditions and postconditions. These specifications 
are referred to as "contracts". The contract for each method will normally 
contain the following pieces of information:

- Acceptable and unacceptable input values
- Return values and their meanings
- Error and exception condition values that can occur during the execution
- Side effects
- Preconditions
- Postconditions
- Invariants

The contract validations are done by <b>assert</b> macros. They have the
responsibility of informing the programmer when a contract can not be validated.

@subsection     spec_prof Profiling 
@note           This feature is not implemented
*/
/*----------------------------------------------------------------------------*/
/** @page       files_org Directory and file organization
@brief          Details about directory and file organization

@tableofcontents
@n
@n
@n
@section        files_intro Intro
The directory structure of eSolid RT Kernel is fairly easy to understand. Once 
the organization of directories and files is understood it is fairly easy to 
integrate eSolid RT Kernel into application.
@subsection     files_porting What is a port?
Porting is a process of adapting software to an architecture that is different 
from the one for which it was originally designed. The term is also used when 
software is changed to make it usable in different environments. Software is 
portable when the cost of porting it to a new platform is less than the cost of
writing it from beginning.

@section        files_sections Code Sections
The kernel is divided into three sections. One section is port independent code,
the second one is port dependent code and the third sections is code templates.
@subsection     files_icode Port independent code
Port independent code is the code which does not change from port to port, e.g.
when the CPU is changed this code is not changed at all and it is still 
correctly executed. Code can be developed and tested on another machine, which
greatly reduces design efforts. It provides API and some common data structures. 
Port independent code lives under @c /inc and @c /src directories:
- @c inc/kernel.h
- @c inc/kernel_cfg.h
- @c src/kernel.c

Click on file name for further description of the file.

@subsection     files_dcode Port dependent code
Second section is the port dependent code. This code provides low-level 
functions which are needed to interact with interrupt controllers, manipulate
CPU settings and do the context switching. They are highly CPU/compiler bounded 
and are often written in assembly language. 

Each port has it's name which is also the name of directory which holds all
the port files. Usually each port has some kind of variant. In that case each 
variant is a subdirectory of the containing port. Common code for all variants
will be in common subdirectory. Each eSolid RT Kernel port will have at least 
the following files:
- <code>port/[port_name]/common/compiler.h</code>
- <code>port/[port_name]/[variant_name]/cpu_cfg.h</code>
- <code>port/[port_name]/[variant_name]/cpu.h</code>
- <code>port/[port_name]/[variant_name]/cpu.c</code>

@note           Port dependent code is separately described in documentation 
for relevant port.
@subsection     files_template Template and example code
Templates are some predefined configuration settings for various scenarios 
where eSolid RT Kernel can be used. Templates also contain some example code 
for how to write new ports. 

In the example below is given @c Generic template which holds files with default 
configuration settings and some example code for new ports. New port files are
in template/generic/port directory. When porting to a new architecture/compiler
use provided template files for starters. This will greatly reduce the time
needed to become familiar with the kernel port requirements. Generic template
files are the following:
- @c template/generic/port/compiler.h
- @c template/generic/port/cpu_cfg.h
- @c template/generic/port/cpu.h
- @c template/generic/port/cpu.c
- @c template/generic/kernel_cfg.h
*/
/*----------------------------------------------------------------------------*/
/** @page       states Kernel states
@brief          Details about kernel states

@tableofcontents
@n
@n
@n
@section        states_intro Intro
A Kernel state machine is a behavior model of the kernel core. Each state
defines which functions can be called and what methods are allowed. 

@section        states_fsm eSolid RT Kernel states
@dot
digraph state {
    size = "6,6";
    node [shape=circle, fontname=Helvetica, fontsize=12, fixedsize="true", width="1.1", height="1.1"];
    nodesep = equally;
    INACTIVE -> INIT [fontname=courier, label=" esKernInit()"];
    INIT -> RUN [fontname=courier, label=" esKernStart()"];
    RUN -> LOCK [fontname=courier, label=" esKernLockEnter() "];
    LOCK -> RUN [fontname=courier, label=" esKernLockExit() "];
    RUN -> INTSRV_RUN [fontname=Helvetica, style=dotted,label=" Int "];
    INTSRV_RUN -> RUN [fontname=Helvetica, style=dotted,label=" Reti "];
    LOCK -> INTSRV_LOCK [fontname=Helvetica, style=dotted, label=" Int "];
    INTSRV_LOCK -> LOCK [fontname=Helvetica, style=dotted, label=" Reti "];
    INTSRV_LOCK -> INTSRV_RUN [fontname=courier, label=" esKernLockExit() "];
    INTSRV_RUN -> INTSRV_LOCK [fontname=courier, label=" esKernLockEnter() "];
    INTSRV_RUN [label="INTSRV\nRUN\n- 1 -"];
    INTSRV_LOCK [label="INTSRV\nLOCK\n- 3 -"];
    INACTIVE [style="bold", label="INACTIVE\n- 5 -"];
    INIT [label="INIT\n- 4 -"];
    RUN [shape=doublecircle, label="RUN\n- 0 -"];
    LOCK [label="LOCK\n- 2 -"];
    {rank = same; RUN; LOCK; }
    {rank = same; INTSRV_RUN; INTSRV_LOCK; }
}
@enddot
@par            INACTIVE
Inactive state of the kernel - Level 5

This state is entered after a physical reset. When the system is in this state 
all the maskable interrupt sources are disabled. In this state none of kernel 
internal data structures are initialized. In this state it is not possible to 
use any Kernel API except esKernInit().

@par            INIT
Initialization state of the kernel - Level 4

In this state all internal data structures are initialized but the kernel is 
still not running. In this stage new threads can be created by calling 
esThdInit() function. Also, the application is allowed to use API which is
used to create kernel structures like Thread Queues @ref esThdQ. All the 
maskable interrupt sources are DISABLED.

@par            RUN
Normal, running state of the kernel - Level 0

To start multi-threading just call the esKernStart() function. This function 
will switch the kernel into @c RUN state and multi-threading of created threads 
will commence. During the @c RUN state you are allowed to create other task as 
well. All the interrupt sources are enabled and the system APIs are accessible, 
threads are running. All the maskable interrupt sources are ENABLED.

@par            LOCK
Scheduler locked state, no context switching - Level 2

The running state of the kernel can be switched to @c LOCK state where the 
scheduler is locked and no context switching is allowed. @c LOCK state is one 
way of preventing the access to a shared resource. One more reason to lock the
scheduler would be during the accessing of special hardware (like programming 
the FLASH memory) which does not allow interruption of the running operation. 
Usage of scheduler locks should be kept at minimum. All the maskable interrupt 
sources are ENABLED.
 
@par            INTSRV
Interrupt Service state, no context switching - Levels 1 and 3

During the both states @c RUN and @c LOCK, an interrupt event can occur. 
When Interrupt Service Routine is executing the kernel is in @c INTSRV_* state. 
Each INTSRV state corresponds to the state where the execution was interrupted 
from and the kernel will return to it's original state.

@note           The level of state @c INACTIVE is the highest. As the kernel
boots up the level is decremented. The running state is level 0.
*/
/*----------------------------------------------------------------------------*/
/** @page       threads Thread Management
@brief          Introduction to threads and how to use them

@tableofcontents
@n
@n
@n
@section        threads_intro Intro
A thread, also called a thread of execution is the smallest sequence of program
instructions that can be managed by an operating system scheduler. 
Multi-threading is usually implemented by time-division multiplexing where the 
processor switches between threads. Context switching occurs fast enough that 
the user perceives the threads as running at the same time. By using threads a
programmer can split the work into the threads, each responsible for a smaller
portion of the problem. From a threads view he thinks it has the processor all 
to itself.

@subsection     kern_threads eSolid RT Kernel thread
eSolid RT Kernel supports multi-threading and allows applications to have any
number of threads. The only limiting factors for the maximum number of threads 
are the amount of RAM and ROM memory and processing time.

@subsection     kern_threads_state Thread states
A thread can be in one of the following states:
@dot
digraph thdState {
    size = "6,6";
    node [shape=circle, fontname=Helvetica, fontsize=12, fixedsize="true", width="1.1", height="1.1"];
    nodesep = equally;
    compound=true;
    inactive -> rdy [fontname=courier, label=" esThdInit() "];
    rdy -> inactive [fontname=courier, label=" esThdTerm()", ltail=cluster0];
    subgraph cluster0 {
        {rank=same; run; rdy;}
        run -> rdy [fontname=courier, label=" schedule "];
        run -> sleep [fontname=courier, label=" esSchedRdyRmI()\n & schedule "];
        rdy -> run [fontname=courier, label=" schedule "];
        rdy -> sleep [fontname=courier, label=" esSchedRdyRmI() "];
        sleep -> rdy [fontname=courier, label=" esSchedRdyAddI() "];
        rdy [label="Ready"];
        run [shape=doublecircle, label="Run"];
        sleep [label="Sleep"];
    }
    inactive [style="bold", label="Inactive"];
}
@enddot
*/
/*----------------------------------------------------------------------------*/
/** @page       critical_section Critical sections
@brief          How to deal with critical sections in an application

@tableofcontents
@n
@n
@n
@section        cs_intro Intro
In concurrent programming, a critical section is a piece of code that accesses a 
shared resource (data structure or device) that must not be concurrently 
accessed by more than one thread of execution. A critical section will usually 
terminate in fixed time, and a thread will have to wait for a fixed time to 
enter it (aka bounded waiting). Some synchronization mechanism is required at 
the entry and exit of the critical section to ensure exclusive use, for example 
a semaphore.

@subsection     kern_critical_sections eSolid RT Kernel internal critical sections
In contrast to application code in kernel code there is no other mechanism to
protect critical code except disabling interrupts. Fortunately, some ports
have ability to mask certain interrupts with low priority and allow 
interrupts with higher priority. By masking low priority interrupts the kernel 
can protect its critical sections. However for this scheme to work its 
forbidden to call any OS service function from a high priority interrupt. If 
this rule is not followed then the high priority interrupt with an OS service 
function call can preempt the kernel low priority interrupt which will in that 
case corrupt the kernel internal data structures.

@note           1) It is forbidden to call any OS service function from an 
    interrupt with the priority higher than the kernel interrupt priority.
@note           2) On some ports the kernel never completely disables interrupts.

@section        cs_implementation Implementation
There are multiple ways how are critical sections implemented:
- The simplest method is to prevent interrupts on entry into the critical 
section, and restoring interrupts to their previous state on exit from critical 
section. Any thread of execution entering any critical section anywhere in the 
system, with this implementation, will prevent any other thread, including an 
interrupt, from being executed on the CPU.
- This approach can be improved upon by using semaphores. To enter a critical 
section, a thread must obtain a semaphore, which it releases on leaving the 
section. Other threads are prevented from entering the critical section at the 
same time as the original thread, but are free to gain control of the CPU and 
execute other code, including other critical sections that are protected by 
different semaphores.

@subsection     cs_interrupt_lock Disabling interrupts
In order to properly disable interrupts the application must follow these steps:
- declare an @c auto variable which will hold interrupt state
- save interrupt status into @c auto variable and disable interrupts
- access the shared resource
- restore previously saved interrupt state

For `auto` variable declaration macro @ref ES_CRITICAL_DECL() is used. This 
macro will declare a temporary interrupt status variable. Then by using the 
macro @ref ES_CRITICAL_ENTER() the state of enabled interrupts will be saved in 
`auto` variable declared earlier. Immediately after saving the interrupt state 
the macro will lock interrupts. Now the code can safely access and use the 
shared resource. When code finishes using the resource it will call
@ref ES_CRITICAL_EXIT() macro. This macro will restore interrupts from the 
previously saved interrupt state.

@code
    ES_CRITICAL_DECL();                 /* Declare an interrupt status variable */
        :
        :
        :   
    ES_CRITICAL_ENTER();                /* Save state and lock interrupts */
    /*
     * Access the shared resource
     */
    ES_CRITICAL_EXIT();                 /* Restore previous state unlocking the interrupts */
@endcode
@par            When to use this scheme

- If interrupt service routine *changes* the shared resource state.
- If the processing time of critical section is very small.

@par            When not to use this scheme

- If interrupt service routine takes a lot of CPU time to process critical 
section. If a critical section is long, then the system clock will drift every 
time a critical section is executed because the system timer interrupt is no 
longer serviced, so tracking time is impossible during the critical section. 
Also, if a program execution halts during its critical section, control will 
never be returned to another thread, effectively halting the entire system.  
 
@subsection     cs_kernel_lock Disabling Kernel
Another way to implement a critical section and protect your data is by locking
the kernel scheduler. The kernel locking can be used only if you know that 
protected data will be modified only by other threads. This protection scheme 
can not be used when data is modified by interrupt service routines.

@code
    esKernLockEnter();                  /* Temporarily disable kernel scheduler  */
    /*
     * Access the shared resource
     */
    esKernLockExit();                   /* Enable kernel scheduler */
@endcode
@par            When to use this scheme

- If interrupt service routine *never changes* the shared resource state.
- If the processing time of critical section is very small.

@par            When not to use this scheme

- If interrupt service routine takes a lot of CPU time to process critical 
section. If a critical section is long, then the system will be partially 
responsive to other events since interrupt service routines can be invoked, but 
note that any further processing by other threads is still disabled. 
 
@subsection     cs_sem_lock Using semaphores
*/
/*----------------------------------------------------------------------------*/
/** @page       time_complexity Time complexity
@brief          About time categories of algorithms

@tableofcontents
@n
@n
@n
@section        tc_intro Intro
In computer science, the time complexity of an algorithm quantifies the amount 
of time taken by an algorithm to run as a function of the length of the input. 
The time complexity of an algorithm is commonly expressed using <b>big O</b> 
notation, which excludes coefficients and lower order terms. When expressed this 
way, the time complexity is said to be described asymptotically, i.e., as the 
input size goes to infinity. For example, if the time required by an algorithm 
on all inputs of size <code>n</code> is at most <code> 5n^3 + 3n</code>, the 
asymptotic time complexity is <code>O(n^3)</code>.

Time complexity is commonly estimated by counting the number of elementary 
operations performed by the algorithm, where an elementary operation takes a 
fixed amount of time to perform. Thus the amount of time taken and the number of 
elementary operations performed by the algorithm differ by at most a constant 
factor.

Since an algorithm’s performance time may vary with different inputs of the same 
size, one commonly uses the worst-case time complexity of an algorithm, denoted 
as <b>T(n)</b>, which is defined as the maximum amount of time taken on any 
input of size <code>n</code>. Time complexities are classified by the nature of 
the function <code>T(n)</code>. For instance, an algorithm with <code>T(n) = 
O(n)</code> is called a linear time algorithm, and an algorithm with <code>T(n) 
= O(2^n)</code> is said to be an exponential time algorithm.

@note  Worst-case time-complexity <code>T(n)</code> indicates the longest 
    running time performed by an algorithm given any input of size 
    <code>n</code>, and thus this guarantees that the algorithm finishes on time.

@subsection     tc_big_o Big O notation

Big O notation describes the limiting behavior of a function when the argument 
tends towards a particular value or infinity, usually in terms of simpler 
functions and it is used to classify algorithms by how they respond (e.g., in 
their processing time or working space requirements) to changes in input size.

@section        tc_constant_time Constant time
An algorithm is said to be constant time (also written as <code>O(1)</code> time) 
if the value of <code>T(n)</code> is bounded by a value that does not depend on 
the size of the input. 

Despite the name <i>"constant time"</i>, the running time does not have to be 
independent of the problem size, but an upper bound for the running time has to 
be bounded independently of the problem size.

@note Constant time effectively means that there is a constant upper bound to 
    how long the function will take to run which isn’t affected by any of the 
    input argument.
    
@subsection        tc_esolid eSolid RT Kernel time complexity
All eSolid RT Kernel functions are using <code>constant time O(1)</code> 
algorithms. This is especially important for Real Time applications.
*/
/*----------------------------------------------------------------------------*/
/** @page       scheduler Scheduler
@brief          About the scheduler and Ready Threads Queue

@tableofcontents
@n
@n
@n
@section        sched_quantum Quantum
The period of time for which a thread is allowed to execute in a preemptive
multi-threading system is generally called the time slice, or @c quantum. The 
scheduler is run once every quantum to choose the next thread for execution. If 
the quantum is too short then the scheduler overhead may become high.

An interrupt is used to allow the kernel to switch between threads when their 
quantum expires, effectively allowing the processor's time to be shared 
between a number of threads, giving the illusion that it is dealing with these 
threads concurrently. 

@section        sched_thdL Threads List
@section        sched_thdQ Threads Queue 
Based on the number of configured priority levels (see @ref CFG_SCHED_PRIO_LVL) 
and on the number of data register bits (see @ref PORT_DATA_WIDTH_VAL) of the 
used CPU, two configurations are possible:
- Simple Ready Threads Queue
- Complex Ready Threads Queue

Simple Ready Threads Queue configuration is used when the number of configured 
priority levels is lower or equal to the number of bits in general purpose data 
register. For example if application is using 9 priority levels on 32-bit CPU 
than simple Ready Threads Queue configuration is used. In contrast, when using 9 
priority levels on an 8-bit CPU than the kernel is forced to use the Complex 
Ready Threads Queue configuration since 8-bit register cannot carry 9 bits of 
data.

@subsection     sched_rdyThdQ_simple Simple Ready Threads Queue
Each bit in <code>bit[0]</code> variable represents each priority level. The 
number of bits used in this variable depends on @ref CFG_SCHED_PRIO_LVL value. 
If a bit at <code>Nth</code> position is set then there is a thread inserted in
Thread List at <code>Nth</code> priority.

@image html     thdQ-simple.png "Ready Threads Queue - low number of priority levels"
@image latex    thdQ-simple.png "Ready Threads Queue - low number of priority levels" width=15cm

@subsection     sched_rdyThdQ_complex Complex Ready Threads Queue
@image html     thdQ-complex.png "Ready Threads Queue - high number of priority levels"
@image latex    thdQ-complex.png "Ready Threads Queue - high number of priority levels" width=17cm

@section        sched_rdyThdQ Ready Threads Queue
Ready Threads Queue holds threads that are ready for execution. 
*/
/*----------------------------------------------------------------------------*/
/** @page       errors Error checking
@brief          How errors are detected

@tableofcontents
@n
@n
@n
@section        errors_intro Intro
*/
